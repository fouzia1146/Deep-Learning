{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa8366c",
   "metadata": {},
   "source": [
    "## Test accuracy on 20 CIFAR-100 classes using Vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f0455",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e174d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 23:16:42.389773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748279802.409701   29203 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748279802.415229   29203 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748279802.429519   29203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748279802.429538   29203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748279802.429540   29203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748279802.429541   29203 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-26 23:16:42.438195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aad24d",
   "metadata": {},
   "source": [
    "###  Load CIFAR-100 fine labels (100-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9ecffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a109bab",
   "metadata": {},
   "source": [
    "### Choose 20 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4d7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = list(range(20))\n",
    "train_mask = np.isin(y_train, selected_classes).flatten()\n",
    "test_mask = np.isin(y_test, selected_classes).flatten()\n",
    "\n",
    "x_train_20 = x_train[train_mask]\n",
    "y_train_20 = y_train[train_mask]\n",
    "x_test_20 = x_test[test_mask]\n",
    "y_test_20 = y_test[test_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9faf3a",
   "metadata": {},
   "source": [
    "### Map label to 0 - 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc25aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {cls: i for i, cls in enumerate(selected_classes)}\n",
    "y_train_20 = np.array([label_map[y[0]] for y in y_train_20])\n",
    "y_test_20 = np.array([label_map[y[0]] for y in y_test_20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b8bdc",
   "metadata": {},
   "source": [
    "### Resize to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "938dce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748279807.795575   29203 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 58 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2025-05-26 23:16:57.832203: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.0KiB (rounded to 1280)requested by op ScratchBuffer\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-05-26 23:16:57.832225: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1058] BFCAllocator dump for GPU_0_bfc\n",
      "2025-05-26 23:16:57.832234: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832246: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832251: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832257: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832262: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832268: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832274: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832279: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832285: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832296: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832302: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832308: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832313: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832319: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832324: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832337: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 58.06MiB allocated for chunks. 58.06MiB in use in bin. 29.30MiB client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832343: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832349: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832355: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:16:57.832360: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1081] Bin for 1.2KiB was 1.0KiB, Chunk State: \n",
      "2025-05-26 23:16:57.832365: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 60882944\n",
      "2025-05-26 23:16:57.832373: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7d0870000000 of size 60882944 next 18446744073709551615\n",
      "2025-05-26 23:16:57.832378: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119]      Summary of in-use Chunks by size: \n",
      "2025-05-26 23:16:57.832385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 60882944 totalling 58.06MiB\n",
      "2025-05-26 23:16:57.832390: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1126] Sum Total of in-use chunks: 58.06MiB\n",
      "2025-05-26 23:16:57.832395: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Total bytes in pool: 60882944 memory_limit_: 60882944 available bytes: 0 curr_region_allocation_bytes_: 121765888\n",
      "2025-05-26 23:16:57.832404: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1133] Stats: \n",
      "Limit:                        60882944\n",
      "InUse:                        60882944\n",
      "MaxInUse:                     60882944\n",
      "NumAllocs:                           1\n",
      "MaxAllocSize:                 60882944\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-05-26 23:16:57.832409: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] ***************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2025-05-26 23:16:57.832473: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: Failed to allocate scratch buffer for device 0\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} Failed to allocate scratch buffer for device 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train_20 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m x_test_20 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(x_test_20, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/MdSourav/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/MdSourav/tf/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} Failed to allocate scratch buffer for device 0"
     ]
    }
   ],
   "source": [
    "x_train_20 = tf.image.resize(x_train_20, (224, 224)).numpy()\n",
    "x_test_20 = tf.image.resize(x_test_20, (224, 224)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe12186",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_20 = preprocess_input(x_train_20)\n",
    "x_test_20 = preprocess_input(x_test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f5d12",
   "metadata": {},
   "source": [
    "### Converts Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_20_cat = tf.keras.utils.to_categorical(y_train_20, 20)\n",
    "y_test_20_cat = tf.keras.utils.to_categorical(y_test_20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5d1f8",
   "metadata": {},
   "source": [
    "### Use Vgg16 + Custom Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f774423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:24:38.882148: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5419008000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:25:12.309519: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n",
      "2025-05-24 16:25:12.496529: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 822083584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 962s 7s/step - loss: 2.9414 - accuracy: 0.4007 - val_loss: 1.1951 - val_accuracy: 0.6660\n",
      "Epoch 2/5\n",
      "141/141 [==============================] - 956s 7s/step - loss: 1.4908 - accuracy: 0.5688 - val_loss: 1.0875 - val_accuracy: 0.6830\n",
      "Epoch 3/5\n",
      "141/141 [==============================] - 957s 7s/step - loss: 1.3249 - accuracy: 0.6164 - val_loss: 1.0489 - val_accuracy: 0.7110\n",
      "Epoch 4/5\n",
      "141/141 [==============================] - 962s 7s/step - loss: 1.1433 - accuracy: 0.6553 - val_loss: 1.0243 - val_accuracy: 0.7490\n",
      "Epoch 5/5\n",
      "141/141 [==============================] - 965s 7s/step - loss: 1.0327 - accuracy: 0.6771 - val_loss: 0.9849 - val_accuracy: 0.7400\n",
      "63/63 [==============================] - 192s 3s/step - loss: 0.9046 - accuracy: 0.7590\n",
      "Test accuracy on 20 CIFAR-100 classes using VGG16: 0.7590000033378601\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  \n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),  \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 9. Train model\n",
    "model.fit(x_train_20, y_train_20_cat, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# 10. Evaluate\n",
    "loss, acc = model.evaluate(x_test_20, y_test_20_cat)\n",
    "print(\"Test accuracy on 20 CIFAR-100 classes using VGG16:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
