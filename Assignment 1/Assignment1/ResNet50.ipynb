{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa8366c",
   "metadata": {},
   "source": [
    "## Test accuracy on 20 CIFAR-100 classes using ResNet50V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4f0455",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 23:43:09.117289: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748281389.252674    7388 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748281389.289589    7388 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748281389.607477    7388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748281389.607497    7388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748281389.607499    7388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748281389.607501    7388 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-26 23:43:09.643736: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.config' has no attribute 'set_virtual_device_configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m         tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mset_memory_growth(gpu, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Optional: set a memory limit (here 8GB)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_virtual_device_configuration\u001b[49m(\n\u001b[1;32m     18\u001b[0m         gpus[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     19\u001b[0m         [tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mVirtualDeviceConfiguration(memory_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8192\u001b[39m)])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntimeError:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.config' has no attribute 'set_virtual_device_configuration'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "\n",
    "# 1. List GPUs and set memory growth & limit BEFORE any TF initialization\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            # Enable memory growtha\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Optional: set a memory limit (here 8GB)\n",
    "        tf.config.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "    except RuntimeError as e:\n",
    "        print(\"RuntimeError:\", e)\n",
    "\n",
    "# 2. Check available devices and memory limits\n",
    "print(\"Available devices and their memory limits:\")\n",
    "for device in device_lib.list_local_devices():\n",
    "    print(f\"{device.name} — {device.device_type} — {device.memory_limit / 1024 / 1024:.2f} MiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aad24d",
   "metadata": {},
   "source": [
    "###  Load CIFAR-100 fine labels (100-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ecffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a109bab",
   "metadata": {},
   "source": [
    "### Choose 20 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = list(range(20))\n",
    "train_mask = np.isin(y_train, selected_classes).flatten()\n",
    "test_mask = np.isin(y_test, selected_classes).flatten()\n",
    "\n",
    "x_train_20 = x_train[train_mask]\n",
    "y_train_20 = y_train[train_mask]\n",
    "x_test_20 = x_test[test_mask]\n",
    "y_test_20 = y_test[test_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9faf3a",
   "metadata": {},
   "source": [
    "### Map label to 0 - 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc25aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {cls: i for i, cls in enumerate(selected_classes)}\n",
    "y_train_20 = np.array([label_map[y[0]] for y in y_train_20])\n",
    "y_test_20 = np.array([label_map[y[0]] for y in y_test_20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b8bdc",
   "metadata": {},
   "source": [
    "### Resize to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938dce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 23:33:39.493211: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.0KiB (rounded to 1280)requested by op ScratchBuffer\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-05-26 23:33:39.493241: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1058] BFCAllocator dump for GPU_0_bfc\n",
      "2025-05-26 23:33:39.493247: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (256): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1024): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493255: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493258: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493261: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493264: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493267: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493269: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493285: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493288: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493293: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493296: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493298: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493301: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493309: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 45.06MiB allocated for chunks. 45.06MiB in use in bin. 29.30MiB client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493312: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493315: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493322: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-05-26 23:33:39.493325: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1081] Bin for 1.2KiB was 1.0KiB, Chunk State: \n",
      "2025-05-26 23:33:39.493328: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 47251456\n",
      "2025-05-26 23:33:39.493332: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 79b86c000000 of size 47251456 next 18446744073709551615\n",
      "2025-05-26 23:33:39.493335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119]      Summary of in-use Chunks by size: \n",
      "2025-05-26 23:33:39.493338: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "{{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} Failed to allocate scratch buffer for device 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train_20 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_20\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      2\u001b[0m x_test_20 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize(x_test_20, (\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m))\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/MdSourav/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/MdSourav/tf/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: {{function_node __wrapped____EagerConst_device_/job:localhost/replica:0/task:0/device:GPU:0}} Failed to allocate scratch buffer for device 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122] 1 Chunks of size 47251456 totalling 45.06MiB\n",
      "2025-05-26 23:33:39.493342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1126] Sum Total of in-use chunks: 45.06MiB\n",
      "2025-05-26 23:33:39.493344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Total bytes in pool: 47251456 memory_limit_: 47251456 available bytes: 0 curr_region_allocation_bytes_: 94502912\n",
      "2025-05-26 23:33:39.493349: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1133] Stats: \n",
      "Limit:                        47251456\n",
      "InUse:                        47251456\n",
      "MaxInUse:                     47251456\n",
      "NumAllocs:                           4\n",
      "MaxAllocSize:                 47251456\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-05-26 23:33:39.493352: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] ******************************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2025-05-26 23:33:39.493369: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: Failed to allocate scratch buffer for device 0\n"
     ]
    }
   ],
   "source": [
    "x_train_20 = tf.image.resize(x_train_20, (128, 128)).numpy()\n",
    "x_test_20 = tf.image.resize(x_test_20, (128, 128)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe12186",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_20 = preprocess_input(x_train_20)\n",
    "x_test_20 = preprocess_input(x_test_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f5d12",
   "metadata": {},
   "source": [
    "### Converts Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_20_cat = tf.keras.utils.to_categorical(y_train_20, 20)\n",
    "y_test_20_cat = tf.keras.utils.to_categorical(y_test_20, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda5d1f8",
   "metadata": {},
   "source": [
    "### Load ResNet50V2 base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f774423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 02:41:57.363303: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1769472000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 129s 900ms/step - loss: 0.9260 - accuracy: 0.7208 - val_loss: 0.5222 - val_accuracy: 0.8240\n",
      "Epoch 2/5\n",
      "141/141 [==============================] - 123s 876ms/step - loss: 0.4528 - accuracy: 0.8481 - val_loss: 0.5207 - val_accuracy: 0.8220\n",
      "Epoch 3/5\n",
      "141/141 [==============================] - 122s 868ms/step - loss: 0.3285 - accuracy: 0.8858 - val_loss: 0.5402 - val_accuracy: 0.8220\n",
      "Epoch 4/5\n",
      "141/141 [==============================] - 122s 868ms/step - loss: 0.2539 - accuracy: 0.9122 - val_loss: 0.5287 - val_accuracy: 0.8350\n",
      "Epoch 5/5\n",
      "141/141 [==============================] - 124s 881ms/step - loss: 0.2061 - accuracy: 0.9258 - val_loss: 0.5398 - val_accuracy: 0.8300\n",
      "63/63 [==============================] - 23s 358ms/step - loss: 0.4656 - accuracy: 0.8595\n",
      "Test accuracy on 20 CIFAR-100 classes using ResNet50: 0.859499990940094\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "base_model.trainable = False  \n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_20, y_train_20_cat, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "loss, acc = model.evaluate(x_test_20, y_test_20_cat)\n",
    "print(\"Test accuracy on 20 CIFAR-100 classes using ResNet50:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
